{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['.git', 'best_model_todate', 'chest_xray', 'web', 'minor.ipynb', 'Beating everything with Depthwise Convolution.ipynb', '.ipynb_checkpoints', 'test']\n"
     ]
    }
   ],
   "source": [
    "# This Python 3 environment comes with many helpful analytics libraries installed\n",
    "# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n",
    "# For example, here's several helpful packages to load in \n",
    "\n",
    "import os\n",
    "import glob\n",
    "import h5py\n",
    "import shutil\n",
    "# import imgaug as aug\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mimg\n",
    "# import imgaug.augmenters as iaa\n",
    "from os import listdir, makedirs, getcwd, remove\n",
    "from os.path import isfile, join, abspath, exists, isdir, expanduser\n",
    "from PIL import Image\n",
    "from pathlib import Path\n",
    "from skimage.io import imread\n",
    "from skimage.transform import resize\n",
    "from keras.models import Sequential, Model\n",
    "from keras.applications.vgg16 import VGG16, preprocess_input\n",
    "from keras.preprocessing.image import ImageDataGenerator,load_img, img_to_array\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Conv2D, MaxPooling2D, Dense, Dropout, Input, Flatten, SeparableConv2D\n",
    "from keras.layers import GlobalMaxPooling2D\n",
    "from keras.layers.normalization import BatchNormalization\n",
    "from keras.layers.merge import Concatenate\n",
    "from keras.models import Model\n",
    "from keras.optimizers import Adam, SGD, RMSprop\n",
    "from keras.callbacks import ModelCheckpoint, Callback, EarlyStopping\n",
    "from keras.utils import to_categorical\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from mlxtend.plotting import plot_confusion_matrix\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import cv2\n",
    "from keras import backend as K\n",
    "color = sns.color_palette()\n",
    "%matplotlib inline\n",
    "\n",
    "# Input data files are available in the \"../input/\" directory.\n",
    "# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n",
    "print(os.listdir(\"./\"))\n",
    "\n",
    "# Any results you write to the current directory are saved as output."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "_cell_guid": "9957d783-26d0-4e21-b8cb-8d1412b66bdd",
    "_uuid": "ee4c0df90c4dfe5f2e770cb3ecf05c849fa6cd7a",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "# Set the seed for hash based operations in python\n",
    "os.environ['PYTHONHASHSEED'] = '0'\n",
    "\n",
    "# Set the numpy seed\n",
    "np.random.seed(111)\n",
    "\n",
    "# Disable multi-threading in tensorflow ops\n",
    "session_conf = tf.compat.v1.ConfigProto(intra_op_parallelism_threads=1, inter_op_parallelism_threads=1)\n",
    "\n",
    "# Set the random seed in tensorflow at graph level\n",
    "tf.compat.v1.set_random_seed(111)\n",
    "\n",
    "# Define a tensorflow session with above session configs\n",
    "sess = tf.compat.v1.Session(graph=tf.compat.v1.get_default_graph(), config=session_conf)\n",
    "\n",
    "# Set the session in keras\n",
    "tf.compat.v1.keras.backend.set_session(sess)\n",
    "\n",
    "# Make the augmentation sequence deterministic\n",
    "# aug.seed(111)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "d488f59675eda4dcdab8aaafaae7263a6128c047"
   },
   "source": [
    "The dataset is divided into three sets: 1) train set    2) validation set    and 3) test set.  Let's grab the dataset   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "_cell_guid": "79c7e3d0-c299-4dcb-8224-4455121ee9b0",
    "_uuid": "d629ff2d2480ee46fbb7e2d37f6b5fab8052498a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['NORMAL', 'PNEUMONIA']\n"
     ]
    }
   ],
   "source": [
    "# # Define path to the data directory\n",
    "data_dir = Path('./chest_xray')\n",
    "\n",
    "# # Path to train directory (Fancy pathlib...no more os.path!!)\n",
    "# train_dir = data_dir / 'train'\n",
    "\n",
    "# # Path to validation directory\n",
    "# val_dir = data_dir / 'val'\n",
    "\n",
    "# # Path to test directory\n",
    "test_dir = data_dir / 'test'\n",
    "print(os.listdir(test_dir))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "_cell_guid": "d2a81adb-fe02-4ec9-bd62-9d183598cf3b",
    "_uuid": "2bad0cc6b4292d08526c433fd86fea32e31e361e"
   },
   "outputs": [],
   "source": [
    "# Get the path to the normal and pneumonia sub-directories\n",
    "# normal_cases_dir = train_dir / 'NORMAL'\n",
    "# pneumonia_cases_dir = train_dir / 'PNEUMONIA'\n",
    "\n",
    "# # Get the list of all the images\n",
    "# normal_cases = normal_cases_dir.glob('*.jpeg')\n",
    "# pneumonia_cases = pneumonia_cases_dir.glob('*.jpeg')\n",
    "\n",
    "# # An empty list. We will insert the data into this list in (img_path, label) format\n",
    "# train_data = []\n",
    "\n",
    "# # Go through all the normal cases. The label for these cases will be 0\n",
    "# for img in normal_cases:\n",
    "#     train_data.append((img,0))\n",
    "\n",
    "# # Go through all the pneumonia cases. The label for these cases will be 1\n",
    "# for img in pneumonia_cases:\n",
    "#     train_data.append((img, 1))\n",
    "\n",
    "# # Get a pandas dataframe from the data we have in our list \n",
    "# train_data = pd.DataFrame(train_data, columns=['image', 'label'],index=None)\n",
    "\n",
    "# # Shuffle the data \n",
    "# train_data = train_data.sample(frac=1.).reset_index(drop=True)\n",
    "\n",
    "# # How the dataframe looks like?\n",
    "# train_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "_cell_guid": "55a1b867-5499-4460-a435-8145c1bdff4e",
    "_uuid": "7339a4be8a266b0d8b13f1f6136370b711691f7a"
   },
   "outputs": [],
   "source": [
    "# # Get the counts for each class\n",
    "# cases_count = train_data['label'].value_counts()\n",
    "# print(cases_count)\n",
    "\n",
    "# # Plot the results \n",
    "# plt.figure(figsize=(10,8))\n",
    "# sns.barplot(x=cases_count.index, y= cases_count.values)\n",
    "# plt.title('Number of cases', fontsize=14)\n",
    "# plt.xlabel('Case type', fontsize=12)\n",
    "# plt.ylabel('Count', fontsize=12)\n",
    "# plt.xticks(range(len(cases_count.index)), ['Normal(0)', 'Pneumonia(1)'])\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "_cell_guid": "294e9c52-2d9a-427c-ba19-c8f3a28b0b65",
    "_uuid": "977e06568660798f12288e7c29bba0fb35646c31"
   },
   "outputs": [],
   "source": [
    "# # Get few samples for both the classes\n",
    "# pneumonia_samples = (train_data[train_data['label']==1]['image'].iloc[:5]).tolist()\n",
    "# normal_samples = (train_data[train_data['label']==0]['image'].iloc[:5]).tolist()\n",
    "\n",
    "# # Concat the data in a single list and del the above two list\n",
    "# samples = pneumonia_samples + normal_samples\n",
    "# del pneumonia_samples, normal_samples\n",
    "\n",
    "# # Plot the data \n",
    "# f, ax = plt.subplots(2,5, figsize=(30,10))\n",
    "# for i in range(10):\n",
    "#     img = imread(samples[i])\n",
    "#     ax[i//5, i%5].imshow(img, cmap='gray')\n",
    "#     if i<5:\n",
    "#         ax[i//5, i%5].set_title(\"Pneumonia\")\n",
    "#     else:\n",
    "#         ax[i//5, i%5].set_title(\"Normal\")\n",
    "#     ax[i//5, i%5].axis('off')\n",
    "#     ax[i//5, i%5].set_aspect('auto')\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "422892036677e8ab0cd5eb1df2a55752611de2a6"
   },
   "source": [
    "### Preparing validation data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "_cell_guid": "4ef15f9a-b9bc-4e00-9ff5-928e287c526e",
    "_uuid": "fa1af0731ad6ff427ff72d9d029a2a414f4d11a3"
   },
   "outputs": [],
   "source": [
    "# # Get the path to the sub-directories\n",
    "# normal_cases_dir = val_dir / 'NORMAL'\n",
    "# pneumonia_cases_dir = val_dir / 'PNEUMONIA'\n",
    "\n",
    "# # Get the list of all the images\n",
    "# normal_cases = normal_cases_dir.glob('*.jpeg')\n",
    "# pneumonia_cases = pneumonia_cases_dir.glob('*.jpeg')\n",
    "\n",
    "# # List that are going to contain validation images data and the corresponding labels\n",
    "# valid_data = []\n",
    "# valid_labels = []\n",
    "\n",
    "\n",
    "# # Some images are in grayscale while majority of them contains 3 channels. So, if the image is grayscale, we will convert into a image with 3 channels.\n",
    "# # We will normalize the pixel values and resizing all the images to 224x224 \n",
    "\n",
    "# # Normal cases\n",
    "# for img in normal_cases:\n",
    "#     img = cv2.imread(str(img))\n",
    "#     img = cv2.resize(img, (224,224))\n",
    "#     if img.shape[2] ==1:\n",
    "#         img = np.dstack([img, img, img])\n",
    "#     img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "#     img = img.astype(np.float32)/255.\n",
    "#     label = to_categorical(0, num_classes=2)\n",
    "#     valid_data.append(img)\n",
    "#     valid_labels.append(label)\n",
    "                      \n",
    "# # Pneumonia cases        \n",
    "# for img in pneumonia_cases:\n",
    "#     img = cv2.imread(str(img))\n",
    "#     img = cv2.resize(img, (224,224))\n",
    "#     if img.shape[2] ==1:\n",
    "#         img = np.dstack([img, img, img])\n",
    "#     img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "#     img = img.astype(np.float32)/255.\n",
    "#     label = to_categorical(1, num_classes=2)\n",
    "#     valid_data.append(img)\n",
    "#     valid_labels.append(label)\n",
    "    \n",
    "# # Convert the list into numpy arrays\n",
    "# valid_data = np.array(valid_data)\n",
    "# valid_labels = np.array(valid_labels)\n",
    "\n",
    "# print(\"Total number of validation examples: \", valid_data.shape)\n",
    "# print(\"Total number of labels:\", valid_labels.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "eba8d9dec36028e4a49ed3b9ffc84f0d94ab861e"
   },
   "source": [
    "## Augmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "_cell_guid": "b38439c7-208b-4495-b994-f9c89449005b",
    "_uuid": "628f0edaefe4da1d55e2e5f022314ebfeed1a2e6"
   },
   "outputs": [],
   "source": [
    "# # Augmentation sequence \n",
    "# seq = iaa.OneOf([\n",
    "#     iaa.Fliplr(), # horizontal flips\n",
    "#     iaa.Affine(rotate=20), # roatation\n",
    "#     iaa.Multiply((1.2, 1.5))]) #random brightness"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "2cbc776086dc1afc6b5d79346f2c29e3451e7273"
   },
   "source": [
    "### Generate Traning Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "_cell_guid": "12f786dc-67b6-409c-95e2-6ccd6ffef39f",
    "_uuid": "2becec172e3fde7839e671416932c36254aafb68"
   },
   "outputs": [],
   "source": [
    "# def data_gen(data, batch_size):\n",
    "#     # Get total number of samples in the data\n",
    "#     n = len(data)\n",
    "#     steps = n//batch_size\n",
    "    \n",
    "#     # Define two numpy arrays for containing batch data and labels\n",
    "#     batch_data = np.zeros((batch_size, 224, 224, 3), dtype=np.float32)\n",
    "#     batch_labels = np.zeros((batch_size,2), dtype=np.float32)\n",
    "\n",
    "#     # Get a numpy array of all the indices of the input data\n",
    "#     indices = np.arange(n)\n",
    "    \n",
    "#     # Initialize a counter\n",
    "#     i =0\n",
    "#     while True:\n",
    "#         np.random.shuffle(indices)\n",
    "#         # Get the next batch \n",
    "#         count = 0\n",
    "#         next_batch = indices[(i*batch_size):(i+1)*batch_size]\n",
    "#         for j, idx in enumerate(next_batch):\n",
    "#             img_name = data.iloc[idx]['image']\n",
    "#             label = data.iloc[idx]['label']\n",
    "            \n",
    "#             # one hot encoding\n",
    "#             encoded_label = to_categorical(label, num_classes=2)\n",
    "#             # read the image and resize\n",
    "#             img = cv2.imread(str(img_name))\n",
    "#             img = cv2.resize(img, (224,224))\n",
    "            \n",
    "#             # check if it's grayscale\n",
    "#             if img.shape[2]==1:\n",
    "#                 img = np.dstack([img, img, img])\n",
    "            \n",
    "#             # cv2 reads in BGR mode by default\n",
    "#             orig_img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "#             # normalize the image pixels\n",
    "#             orig_img = img.astype(np.float32)/255.\n",
    "            \n",
    "#             batch_data[count] = orig_img\n",
    "#             batch_labels[count] = encoded_label\n",
    "            \n",
    "#             # generating more samples of the undersampled class\n",
    "#             if label==0 and count < batch_size-2:\n",
    "#                 aug_img1 = seq.augment_image(img)\n",
    "#                 aug_img2 = seq.augment_image(img)\n",
    "#                 aug_img1 = cv2.cvtColor(aug_img1, cv2.COLOR_BGR2RGB)\n",
    "#                 aug_img2 = cv2.cvtColor(aug_img2, cv2.COLOR_BGR2RGB)\n",
    "#                 aug_img1 = aug_img1.astype(np.float32)/255.\n",
    "#                 aug_img2 = aug_img2.astype(np.float32)/255.\n",
    "\n",
    "#                 batch_data[count+1] = aug_img1\n",
    "#                 batch_labels[count+1] = encoded_label\n",
    "#                 batch_data[count+2] = aug_img2\n",
    "#                 batch_labels[count+2] = encoded_label\n",
    "#                 count +=2\n",
    "            \n",
    "#             else:\n",
    "#                 count+=1\n",
    "            \n",
    "#             if count==batch_size-1:\n",
    "#                 break\n",
    "            \n",
    "#         i+=1\n",
    "#         yield batch_data, batch_labels\n",
    "            \n",
    "#         if i>=steps:\n",
    "#             i=0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "_cell_guid": "118d98a9-c5f4-4288-bf41-a67080657af2",
    "_uuid": "6288e9af327d72237ec04364ae5d14ff1d490061"
   },
   "outputs": [],
   "source": [
    "def build_model():\n",
    "    input_img = Input(shape=(224,224,3), name='ImageInput')\n",
    "    x = Conv2D(64, (3,3), activation='relu', padding='same', name='Conv1_1')(input_img)\n",
    "    x = Conv2D(64, (3,3), activation='relu', padding='same', name='Conv1_2')(x)\n",
    "    x = MaxPooling2D((2,2), name='pool1')(x)\n",
    "    \n",
    "    x = SeparableConv2D(128, (3,3), activation='relu', padding='same', name='Conv2_1')(x)\n",
    "    x = SeparableConv2D(128, (3,3), activation='relu', padding='same', name='Conv2_2')(x)\n",
    "    x = MaxPooling2D((2,2), name='pool2')(x)\n",
    "    \n",
    "    x = SeparableConv2D(256, (3,3), activation='relu', padding='same', name='Conv3_1')(x)\n",
    "    x = BatchNormalization(name='bn1')(x)\n",
    "    x = SeparableConv2D(256, (3,3), activation='relu', padding='same', name='Conv3_2')(x)\n",
    "    x = BatchNormalization(name='bn2')(x)\n",
    "    x = SeparableConv2D(256, (3,3), activation='relu', padding='same', name='Conv3_3')(x)\n",
    "    x = MaxPooling2D((2,2), name='pool3')(x)\n",
    "    \n",
    "    x = SeparableConv2D(512, (3,3), activation='relu', padding='same', name='Conv4_1')(x)\n",
    "    x = BatchNormalization(name='bn3')(x)\n",
    "    x = SeparableConv2D(512, (3,3), activation='relu', padding='same', name='Conv4_2')(x)\n",
    "    x = BatchNormalization(name='bn4')(x)\n",
    "    x = SeparableConv2D(512, (3,3), activation='relu', padding='same', name='Conv4_3')(x)\n",
    "    x = MaxPooling2D((2,2), name='pool4')(x)\n",
    "    \n",
    "    x = Flatten(name='flatten')(x)\n",
    "    x = Dense(1024, activation='relu', name='fc1')(x)\n",
    "    x = Dropout(0.7, name='dropout1')(x)\n",
    "    x = Dense(512, activation='relu', name='fc2')(x)\n",
    "    x = Dropout(0.5, name='dropout2')(x)\n",
    "    x = Dense(2, activation='softmax', name='fc3')(x)\n",
    "    \n",
    "    model = Model(inputs=input_img, outputs=x)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "_cell_guid": "37863ed3-1814-437d-8db1-7d56283f0a87",
    "_uuid": "b34d477061729a390c947d4b9ee2473b068294ec"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Large dropout rate: 0.7 (>0.5). In TensorFlow 2.x, dropout() uses dropout rate instead of keep_prob. Please ensure that this is intended.\n",
      "Model: \"model_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "ImageInput (InputLayer)      (None, 224, 224, 3)       0         \n",
      "_________________________________________________________________\n",
      "Conv1_1 (Conv2D)             (None, 224, 224, 64)      1792      \n",
      "_________________________________________________________________\n",
      "Conv1_2 (Conv2D)             (None, 224, 224, 64)      36928     \n",
      "_________________________________________________________________\n",
      "pool1 (MaxPooling2D)         (None, 112, 112, 64)      0         \n",
      "_________________________________________________________________\n",
      "Conv2_1 (SeparableConv2D)    (None, 112, 112, 128)     8896      \n",
      "_________________________________________________________________\n",
      "Conv2_2 (SeparableConv2D)    (None, 112, 112, 128)     17664     \n",
      "_________________________________________________________________\n",
      "pool2 (MaxPooling2D)         (None, 56, 56, 128)       0         \n",
      "_________________________________________________________________\n",
      "Conv3_1 (SeparableConv2D)    (None, 56, 56, 256)       34176     \n",
      "_________________________________________________________________\n",
      "bn1 (BatchNormalization)     (None, 56, 56, 256)       1024      \n",
      "_________________________________________________________________\n",
      "Conv3_2 (SeparableConv2D)    (None, 56, 56, 256)       68096     \n",
      "_________________________________________________________________\n",
      "bn2 (BatchNormalization)     (None, 56, 56, 256)       1024      \n",
      "_________________________________________________________________\n",
      "Conv3_3 (SeparableConv2D)    (None, 56, 56, 256)       68096     \n",
      "_________________________________________________________________\n",
      "pool3 (MaxPooling2D)         (None, 28, 28, 256)       0         \n",
      "_________________________________________________________________\n",
      "Conv4_1 (SeparableConv2D)    (None, 28, 28, 512)       133888    \n",
      "_________________________________________________________________\n",
      "bn3 (BatchNormalization)     (None, 28, 28, 512)       2048      \n",
      "_________________________________________________________________\n",
      "Conv4_2 (SeparableConv2D)    (None, 28, 28, 512)       267264    \n",
      "_________________________________________________________________\n",
      "bn4 (BatchNormalization)     (None, 28, 28, 512)       2048      \n",
      "_________________________________________________________________\n",
      "Conv4_3 (SeparableConv2D)    (None, 28, 28, 512)       267264    \n",
      "_________________________________________________________________\n",
      "pool4 (MaxPooling2D)         (None, 14, 14, 512)       0         \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 100352)            0         \n",
      "_________________________________________________________________\n",
      "fc1 (Dense)                  (None, 1024)              102761472 \n",
      "_________________________________________________________________\n",
      "dropout1 (Dropout)           (None, 1024)              0         \n",
      "_________________________________________________________________\n",
      "fc2 (Dense)                  (None, 512)               524800    \n",
      "_________________________________________________________________\n",
      "dropout2 (Dropout)           (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "fc3 (Dense)                  (None, 2)                 1026      \n",
      "=================================================================\n",
      "Total params: 104,197,506\n",
      "Trainable params: 104,194,434\n",
      "Non-trainable params: 3,072\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model =  build_model()\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "_cell_guid": "556f2cd2-a824-498a-afad-824dc4d7a951",
    "_uuid": "6ca55c4ce3478d075c36dbf29d3d1890ef6d301f"
   },
   "outputs": [],
   "source": [
    "# # Open the VGG16 weight file\n",
    "# f = h5py.File('../input/vgg16/vgg16_weights_tf_dim_ordering_tf_kernels_notop.h5', 'r')\n",
    "\n",
    "# # Select the layers for which you want to set weight.\n",
    "\n",
    "# w,b = f['block1_conv1']['block1_conv1_W_1:0'], f['block1_conv1']['block1_conv1_b_1:0']\n",
    "# model.layers[1].set_weights = [w,b]\n",
    "\n",
    "# w,b = f['block1_conv2']['block1_conv2_W_1:0'], f['block1_conv2']['block1_conv2_b_1:0']\n",
    "# model.layers[2].set_weights = [w,b]\n",
    "\n",
    "# w,b = f['block2_conv1']['block2_conv1_W_1:0'], f['block2_conv1']['block2_conv1_b_1:0']\n",
    "# model.layers[4].set_weights = [w,b]\n",
    "\n",
    "# w,b = f['block2_conv2']['block2_conv2_W_1:0'], f['block2_conv2']['block2_conv2_b_1:0']\n",
    "# model.layers[5].set_weights = [w,b]\n",
    "\n",
    "# f.close()\n",
    "# model.summary()    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "_cell_guid": "87cd9cae-b836-4470-84fd-56a83f5e82c8",
    "_uuid": "15295c609c87c11f943aa0ed24055ca65bbd57f2"
   },
   "outputs": [],
   "source": [
    "# # opt = RMSprop(lr=0.0001, decay=1e-6)\n",
    "opt = Adam(lr=0.0001, decay=1e-5)\n",
    "es = EarlyStopping(patience=5)\n",
    "# chkpt = ModelCheckpoint(filepath='best_model_todate', save_best_only=True, save_weights_only=True)\n",
    "model.compile(loss='binary_crossentropy', metrics=['accuracy'],optimizer=opt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "_cell_guid": "0c4b5c2d-d344-465c-8d20-3c628ed19292",
    "_uuid": "890ed0a4de401a42bf54bbecb58f105a360d3c7d"
   },
   "outputs": [],
   "source": [
    "# batch_size = 16\n",
    "# nb_epochs = 20\n",
    "\n",
    "# # Get a train data generator\n",
    "# train_data_gen = data_gen(data=train_data, batch_size=batch_size)\n",
    "\n",
    "# # Define the number of training steps\n",
    "# nb_train_steps = train_data.shape[0]//batch_size\n",
    "\n",
    "# print(\"Number of training and validation steps: {} and {}\".format(nb_train_steps, len(valid_data)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "_cell_guid": "7005e3d2-0b62-4f14-8def-ef0af971b6fd",
    "_uuid": "0cfc4e08fdea211ff50c400b143dad1be126e226"
   },
   "outputs": [],
   "source": [
    "# # Fit the model\n",
    "# history = model.fit_generator(train_data_gen, epochs=nb_epochs, steps_per_epoch=nb_train_steps,\n",
    "#                               validation_data=(valid_data, valid_labels),callbacks=[es, chkpt],\n",
    "#                               class_weight={0:1.0, 1:0.4})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "_uuid": "f8af9aee46133b89e02c825cea1a0fcdf801eac0"
   },
   "outputs": [],
   "source": [
    "# Load the model weights\n",
    "model.load_weights(\"./best_model_todate\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "_cell_guid": "7e366caa-87e1-4761-aaca-5d87dee2605f",
    "_uuid": "135d485c94679ae8942fc0e372091d914b752b55"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<generator object Path.glob at 0x7f5a331f0db0>\n",
      "Total number of test examples:  (624, 224, 224, 3)\n",
      "Total number of labels: (624, 2)\n"
     ]
    }
   ],
   "source": [
    "# Preparing test data\n",
    "normal_cases_dir = test_dir / 'NORMAL'\n",
    "pneumonia_cases_dir = test_dir / 'PNEUMONIA'\n",
    "\n",
    "normal_cases = normal_cases_dir.glob('*.jpeg')\n",
    "pneumonia_cases = pneumonia_cases_dir.glob('*.jpeg')\n",
    "test_data = []\n",
    "test_labels = []\n",
    "\n",
    "for img in normal_cases:\n",
    "    print(img)\n",
    "    img = cv2.imread(str(img))\n",
    "    img = cv2.resize(img, (224,224))\n",
    "    if img.shape[2] ==1:\n",
    "        img = np.dstack([img, img, img])\n",
    "    else:\n",
    "        img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "    img = img.astype(np.float32)/255.\n",
    "    label = to_categorical(0, num_classes=2)\n",
    "    test_data.append(img)\n",
    "    test_labels.append(label)\n",
    "                      \n",
    "for img in pneumonia_cases:\n",
    "    img = cv2.imread(str(img))\n",
    "    img = cv2.resize(img, (224,224))\n",
    "    if img.shape[2] ==1:\n",
    "        img = np.dstack([img, img, img])\n",
    "    else:\n",
    "        img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "    img = img.astype(np.float32)/255.\n",
    "    label = to_categorical(1, num_classes=2)\n",
    "    test_data.append(img)\n",
    "    test_labels.append(label)\n",
    "    \n",
    "\n",
    "test_data = np.array(test_data)\n",
    "test_labels = np.array(test_labels)\n",
    "\n",
    "print(\"Total number of test examples: \", test_data.shape)\n",
    "print(\"Total number of labels:\", test_labels.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "_cell_guid": "65afc715-9f5b-4a3a-b2a9-053bd271ba94",
    "_uuid": "8032be06a247d736a041f83f0f78d74ee0310a86"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "624/624 [==============================] - 70s 111ms/step\n",
      "Loss on test set:  0.7698091609703485\n",
      "Accuracy on test set:  0.7820512652397156\n"
     ]
    }
   ],
   "source": [
    "# Evaluation on test dataset\n",
    "test_loss, test_score = model.evaluate(test_data, test_labels, batch_size=16)\n",
    "print(\"Loss on test set: \", test_loss)\n",
    "print(\"Accuracy on test set: \", test_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "_uuid": "5bfc1e8956055abdb5d5bb3399509864aa635ba6"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(624,)\n",
      "[0 1 1 0 1 0 0 0 0 1 1 1 0 0 0 1 1 1 0 0 0 1 1 1 1 0 1 1 1 0 1 1 1 1 1 1 1\n",
      " 1 1 1 0 1 0 0 1 0 0 0 0 1 1 0 0 1 1 1 0 1 1 1 0 1 1 1 1 0 1 1 0 0 0 1 1 1\n",
      " 1 1 1 1 1 1 0 0 0 1 1 0 1 0 1 1 1 0 1 1 0 1 1 1 1 1 1 0 0 1 0 1 1 0 1 0 0\n",
      " 1 1 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 1 0 0 0 1 0 1 0 1 0 1 0 1 0 0 1 0 0 1 0\n",
      " 0 0 0 1 1 0 0 0 1 0 1 1 0 1 0 1 0 0 0 0 1 1 0 0 1 1 1 1 1 0 0 0 0 0 0 1 0\n",
      " 1 1 1 1 1 0 1 0 1 0 0 0 0 0 1 1 0 1 0 1 1 1 1 1 0 1 0 1 0 0 0 1 1 1 1 0 1\n",
      " 0 0 1 1 1 1 0 1 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]\n"
     ]
    }
   ],
   "source": [
    "# Get predictions\n",
    "preds = model.predict(test_data, batch_size=16)\n",
    "preds = np.argmax(preds, axis=-1)\n",
    "\n",
    "# Original labels\n",
    "orig_test_labels = np.argmax(test_labels, axis=-1)\n",
    "\n",
    "print(orig_test_labels.shape)\n",
    "print(preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "_uuid": "7a0944856f2d0666cf7c4fd90ad3e690ed17b2e7"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Figure size 432x288 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 864x576 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Get the confusion matrix\n",
    "cm  = confusion_matrix(orig_test_labels, preds)\n",
    "plt.figure()\n",
    "plot_confusion_matrix(cm,figsize=(12,8), hide_ticks=True,cmap=plt.cm.Blues)\n",
    "plt.xticks(range(2), ['Normal', 'Pneumonia'], fontsize=16)\n",
    "plt.yticks(range(2), ['Normal', 'Pneumonia'], fontsize=16)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "_uuid": "7429c904fed42eacc83dc385a7c83b1c47b64183"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Recall of the model is 0.99\n",
      "Precision of the model is 0.75\n"
     ]
    }
   ],
   "source": [
    "# Calculate Precision and Recall\n",
    "tn, fp, fn, tp = cm.ravel()\n",
    "\n",
    "precision = tp/(tp+fp)\n",
    "recall = tp/(tp+fn)\n",
    "\n",
    "print(\"Recall of the model is {:.2f}\".format(recall))\n",
    "print(\"Precision of the model is {:.2f}\".format(precision))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
